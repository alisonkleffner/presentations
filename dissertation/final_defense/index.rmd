---
title: "Visualization and Modeling of Multivariate Data in Environmental Applications"
subtitle: "PhD Final Examination"
author: "Alison Kleffner"
date: "Department of Statistics, University of Nebraska - Lincoln"
output:
  xaringan::moon_reader:
    seal: true
    includes:
      after_body:
        "js-addins.html"
    #mathjax: "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML"
    css: ["default", "metropolis-fonts", "metropolis" ,"css/modal.css", "css/sizeformat.css"]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightlines: true
      countIncrementalSlides: true
---
class:primary

```{r, child = "style.Rmd"}
```


```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
# Packages
library(emoji)
library(purrr)
library(tidyverse)
library(gridExtra)
library(nullabor)
library(scales)
library(knitr)
library(kableExtra)
library(RefManageR)
library(iconr)
library(fontawesome)
library(shiny)

# download_fontawesome()

# References
bib <- ReadBib("bib/thesis.bib")
ui <- "- "

# R markdown options
knitr::opts_chunk$set(echo = FALSE, 
                      message = FALSE, 
                      warning = FALSE, 
                      cache = TRUE,
                      dpi = 300)
options(htmltools.dir.version = FALSE)
options(knitr.kable.NA = '')
```

```{r, include = F, eval = T, cache = T}
clean_file_name <- function(x) {
  basename(x) %>% str_remove("\\..*?$") %>% str_remove_all("[^[A-z0-9_]]")
}
img_modal <- function(src, alt = "", id = clean_file_name(src), other = "") {
  
  other_arg <- paste0("'", as.character(other), "'") %>%
    paste(names(other), ., sep = "=") %>%
    paste(collapse = " ")
  
  js <- glue::glue("<script>
        /* Get the modal*/
          var modal{id} = document.getElementById('modal{id}');
        /* Get the image and insert it inside the modal - use its 'alt' text as a caption*/
          var img{id} = document.getElementById('img{id}');
          var modalImg{id} = document.getElementById('imgmodal{id}');
          var captionText{id} = document.getElementById('caption{id}');
          img{id}.onclick = function(){{
            modal{id}.style.display = 'block';
            modalImg{id}.src = this.src;
            captionText{id}.innerHTML = this.alt;
          }}
          /* When the user clicks on the modalImg, close it*/
          modalImg{id}.onclick = function() {{
            modal{id}.style.display = 'none';
          }}
</script>")
  
  html <- glue::glue(
     " <!-- Trigger the Modal -->
<img id='img{id}' src='{src}' alt='{alt}' {other_arg}>
<!-- The Modal -->
<div id='modal{id}' class='modal'>
  <!-- Modal Content (The Image) -->
  <img class='modal-content' id='imgmodal{id}'>
  <!-- Modal Caption (Image Text) -->
  <div id='caption{id}' class='modal-caption'></div>
</div>
"
  )
  write(js, file = "js-addins.html", append = T)
  return(html)
}
# Clean the file out at the start of the compilation
write("", file = "js-addins.html")
```

# Outline


`r fa_i("arrows")` Overall Motivation

`r fa_i("list")` Redesinging Yield Map Plots for Comprehension and Usability

`r fa_i("info")` Visual Diagnostics for Trajectory Data

`r fa_i("spinner")` Spatio-Temporal Model for Arctic Sea Ice

`r fa_i("check-double")` References

---
class:primary
# Overall Motivation


The rapid development of technology, like global position systems (GPS) and geographic information systems (GIS), has led to a dramatic increase in the amount of spatial and spatio-temporal data collected `r Citep(bib[[c("ansari_spatiotemporal_2020")]])` 

+ This growth has necessitated the development of new techniques to work with this data `r Citep(bib[[c("yuan_review_2017")]])`
+ We focus on environmental applications with multivariate spatial data and trajectory data.


???
The development of technology like global positioning systems and geographic information systems has dramatically increased the amount of spatial and spatio-temporal data that are able to be easily collected. Hence, new techniques have been needed to work with this data that accurately account for relationships over space and through time, while. Further, the new techniques need to be able to work with large amounts of data. This data can be broken into different sub-categories, so for this work we focus on multivariate spatial data and trajectories used in different applications related to the environment. 

---
class:inverse
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
.center[
# Multivariate Spatial Data: Redesigning Yield Map Plots for Comprehension and Usability
]


---
class:primary
# Spatial Data

Spatial data relates to a geographical area or location.
+ Patterns in spatial data follow Tobler’s first law of geography, meaning everything is
related but near things are more related than distant things `r Citep(bib[[c("klippel-tobler-2011")]])` 
+ Often, more than one attribute is measured at a location. 

**Focus:** However, due to the variables occupying the same space, multivariate spatial data is complex, making it especially difficult to visualize due to issues like clutter `r Citep(bib[[c("he-mult-2019")]])`

**Example:** Visualization of crop input application versus crop yield

???

This first project focuses on spatial data, specifically multivariate spatial data. Spatial data relates to a geographical area or location. Following Tobler's law of geography says that all spatial data is related, but near objects are more related than distant objects. Often more than one temperature is measured at a location, like rainfall and temperature across the state of Nebraska. Not only can accurately account for the relationship though space be difficult, but the variables in a multivariate spatial data set occupying the same space adds to the complexity. This makes visualization especially difficult to issues like clutter. In this project I explore spatial visualizations for deriving a relationship between two variables, specifically crop input application and crop yield.

---
class:primary
#Background

+ With a projected increase in future crop demand, researchers are conducting studies on crop input application to increase yield, focusing on sustainability `r Citep(bib[[c("tilman_sustainalbe_2011")]])` 
+ Crop Input Example: Nitrogen Fertilizer
  - Nitrogen is an essential component of food production as allows plants to photosynthesize efficiently `r Citep(bib[[c("MAHESWARI2017175")]])`  
  - Nearly half of the nitrogen fertilizer supplied to the field is not used by the crops `r Citep(bib[[c("billen_nitrogen_2013")]])` 
  - This excess nitrogen can be harmful
+ Hence, research needs to be conducted on determining input rates that increase crop yield, and are also more sustainable.

.center[
```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i1 <- img_modal(src = "images/tractor.png", alt = "Tractor",other=list(width="40%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```

]

???

I'm going to begin by motivating why we want to understand this relationship. There is a projected increase in future crop demand, so studies are be conducted on crop input application to increase yield, with a focus on sustainable practices. As an example, a common crop input in nitrogen fertilizer as nitrogen is an essential component of food production, as it allows plants to photosynthesize efficiently. However, nearly half of the fertilizer supplied to the field is not used by the crops. This excess nitrogen can be harmful, as an example, the excess nitrogen may get washed in the rain into nearby streams, polluting drinking water. So a better understanding of this relationship is needed to not use more crop input than necessary. 

---
class:primary
# Data Intensive Farm Management (DIFM)

**Problem**: Address inefficient application of crop inputs to farm fields worldwide

**Methods**: On-Farm Precision Experimentation
- Conduct experiments using site-specific inputs 
- GPS-reliant technology 

**Goals**
- Develop infrastructure to develop and analyze these experiments
- Find economically optimal application rate to increase profit while reducing environmental impacts. 

[Project Website](http://difm-cig.org/)

.center[
```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i1 <- img_modal(src = "images/logo.png", alt = "Data Intensive Farma Management (DIFM) Project",other=list(width="30%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```

]

???

The purpose of the data intensive farm management project, a grant funded by the USDA-NRCS, is to generate the data necessary to understand this effect of crop input application on yield, so a more optimal level can be chosen. The data is generated through the use of On-Farm precision experimentation (OFPE). In an OFPE experiments are conducted on a field using field specific inputs where the experiment is implemented using a tractor that has GPS-reliant technology. DIFM wants to develop infrastructure to easily develop and analyze these experiments, with the end goal of finding economically optimal application rate to increase profits while reducing environmental impacts. 

---
class:primary
# Trial Design and Data Collection

.pull-left[
**Step 1**: Develop infrastructure to develop experiments using site-specific inputs

[Trial Design Tool](http://trialdesign.difm-cig.org/)

.center[
```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}

i2 <- img_modal(src = "images/Trial_Design.png", alt = "Example of A Trial Design", other=list(width="75%"))

c(str_split(i2, "\\n", simplify = T)[1:2],
  str_split(i2, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```
]

**Output**: shape files that can be put into a farmer's tractor that allows them to carry out the experiments

].pull-right[

**Step 2**: Conduct experiments and collect data

.center[
```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i1 <- img_modal(src = "images/data_collection.png", alt = "How Data is collected",other=list(width="45%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```
]

Examples of Data Collected:
- As-applied
- Yield
- Location of measurements

]

???

Next, I am going to talk about the data we used and how it was collected. So, the first step was to develop infrastructure that allows for the development of experiments using site-specific inputs. After the user is satisfied with the trial design, they can download shape files that can be put into a farmer's tractor that allows them to carry out the experiments. The data we used in our plots includes the original trial design. Additionally the as-applied data was collected, or the amount of crop input that was actually applied to the field. The clear circles on this image are locations where the tractor used the crop input. So we are able to obtain the actual amount applied and the location of the measurement. Finally, after harvest we are able to obtain the yield measurements and their locations (yellow dots).  

---
class:primary
# Explain the Results

**Step 3**: Explain the optimal management decisions


**How**: create a user interface, designed around explaining machine learning output to non-experts
  - Build trust in models
  - Learn how crop yield responds to different input application rates, field characteristics, and weather to hopefully increase profits. 
  
  
**One way to do this**: Visually explore the relationship between input application and yield through a graph
  - Show the spatial correlations between the application/treatment and yield in a way that is understandable to farmers and consultants. 
  - Develop perceptually optimal plots that communication this relationship. 
  
**Next**: Sub-optimal design choices in current plots
  
???

The last step in this process is to analyze the data and explain the optimal decision management decisions. Eventually we want to develop an user interface that is designed around explaining the machine learning output to non-experts to help inform decision. We want to do this to build farmer's trust in the models. Additionally, as a whole this will help us learn how crop yield responds to different input application rates, field characteristics, and weather with the goal to help increase profits. One way to help build trust in model output is to allows the farmers to visually explore the relationship between crop input application and yield. There is a great benefit of plotting data, so we wanted to explore this relationship visually. Hence, we want to show the spatial correlations between the treatment application and yield in a way that is understandable to farmers and consultants. Additionally, we need to develop these plots so they are perceptually optimal.  

---
class:primary
#Layout: Superimposed Graphs

**Benefits**: Easier to compare as users can use perception rather than memory
- Useful when spatial location is a key component of the comparison `r Citep(bib[[c("wang_comp18")]])`

**Drawback**: clutter

.pull-left[
.center[
```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i1 <- img_modal(src = "images/old_map.png", alt = "Example 1", other=list(width="70%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```
]

].pull-right[
+ Multiple dots on top of one another
  - Obscures true number of dots, harder to find patterns
  - Visual cues, like color, becomes partially obstructed, thereby reducing search efficiency `r Citep(bib[[c("BRAVO2004b", "BRAVO2004a")]])`
  - Can overburden human perception, causing errors in performing tasks `r Citep(bib[[c("huang2009")]])`
]  



???

So in more detail, the superimposed graphs violate a general principle, which is to show the data clearly. As we can seen in this plot, multiple of the yield measurements are found on top of one another, which obscures the true number of points and make it more difficult to find a pattern. Obscuring the visual cue of color reduces search efficiency. Further, the clutter can overburden the human perceptual system, causing errors in deriving a relationship between the variables.

---
class:primary
#Layout: Juxtaposed Graphs

**Benefits**: less issues with visual clutter and easier to create `r Citep(bib[[c("gleicher2011")]])`

**Drawback**: Most of the comparative burden placed on users' memory
+ A mental image is relied on for comparison in these scenarios, as the user moves their
eyes between images (shifting focus). 
  - The plot contents may not be accurately formed in working memory, leading to potential errors when deriving patterns  `r Citep(bib[[c("vanderplas2020", "lyi2021")]])`
+ Lack of visual cues for locations


.center[
```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i1 <- img_modal(src = "images/juxtaposed-ex.jpeg", alt = "Juxtaposed Example", other=list(width="35%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```

]

???

With Juxtaposed graphs, once again, most of the comparative burden is place on the user's memory. A mental image is relied upon as the user shifts their focus between the plots. So if the plot contents are not accurately formed in working memory, the user may incorrectly derive patterns. Also, in spatial visualizations, the lack of visual cues adds to this complexity.

---
class:primary
#Color Schemes

.pull-left[
+ Red-green color blindness
  - Difficult to discriminate between these colors `r Citep(bib[[c("wong2011color")]])` 
  

+ Stop-Light Color Scheme
  - Yellow has a highlighting effect
  - Univariate Scale more appropriate
  

+ Same Color scheme for multiple variables
  - May cause confusion
  

+ Rainbow Color Scheme 
  - No inherent ordering of magnitude `r Citep(bib[[c("light-rainbow-2004")]])` 
  - Extremes are visually close`r Citep(bib[[c("SILVA2011320")]])` 
  
].pull-right[
.center[
```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i1 <- img_modal(src = "images/maxwell.png", alt = "Maxwell et al (2018)", other=list(width="45%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```


```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}

i1 <- img_modal(src = "images/trevisan.png", alt = "Trevisan et al (2021)", other=list(width="45%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```

]
]

**Next:** Redesign Process

???

Red-green color blindness is experienced by approximately 8% of men and 0.5% of northern european ancestory
Another common issue among these graphs is choosing a good color palette. First, red-green color blindness makes it difficult to discriminate between these colors, so we should not use them in conjunction, which many of the plots did. Next, the stop-light color scheme should be avoided, as first yellow can have a highlighting effect. Also, a univariate scale would be more appropriate since we are only working with magnitude of our variables. Third, using the same color scheme for multiple variables should be avoided as this may cause confusion. Finally, rainbow color schemes should not be used as they have no inherent ordering of magnitdue and as we saw previously, the extremes of red and violet are visually close.


---
class:primary
#Redesign: Color Blending

.center[
```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i1 <- img_modal(src = "images/Attempt1.png", alt = "First Iteration", other=list(width="35%"))
i2 <- img_modal(src = "images/Attempt2.png", alt = "Second Iteration", other=list(width="35%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i2, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9],
  str_split(i2, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```
]

**Focus**: Superimpose the treatment and yield plots, while reducing the clutter 
+ Use of transparency to show both at same time
+ Working on blending using transparency



???

I chose to use superimpose plots as spatial location is a key component of our comparison, and we are already asking our user to do a complicated task. So the focus turns to reducing the visual clutter.
My first iteration used the yield points that were transformed into polygons using the distance between points, swath width, and heading (green space around plot). These are the same polygons used in the juxtaposed DIFM plots, so now we have non-overlapping polygons of the yield. Through the literature a common suggestion for these plots is to use transparency to try and blend the colors. So I introduced transparency to the trial design layer to help blend the colors. I started with using similar colors schemes as the original DIFM plots to help obtain buy in (first plot). However, due to potentially having users who are red-green. A suggestion by Wong (2011) is to change green to blue, so that was what was done here. So at least one of the colors are the default. However, in my personal opinion, the blending needs more work and deriving relationships is difficult.

---
class:primary
#Redesign: Bivariate Color Plot

**Alternative to color blending**

.center[

.pull-left[

```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i1 <- img_modal(src = "images/color-map4.png", alt = "Bivariate Color Map", other=list(width="100%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```
]].pull-right[

+ **Benefit**: relationship between the variables is most important `r Citep(bib[[c("elmer2013symbol")]])` 
+ Recommendation: 3x3 scale `r Citep(bib[[c("Leonowicz2003RESEARCHOT")]])`  
  - + Quantiles `r Citep(bib[[c("biesecker-2020")]])`   
+ **Focus**: diagonal
  - Diagonal: grayscale color scheme. 
  - Upper left and lower right: complementary color scheme `r Citep(bib[[c("strode-2020")]])`
+ **Drawback**: Lose more detailed information


]

???

A suggestion for an alternative to color blending is a bivariate color plot. A benefit of this plot is that it is helpful if showing the relationship between variables is more important. Leonowicz (2003) suggests a 3x3 scale, where the data was split using quantiles as suggested by Bieskecker (2020), as they found quantiles lead to more perceptual visual groupings. In this plots, the focus is on the diagonal, so a grayscale color scheme was used here, and the lower/upper corners have complementary color schemes. Typically focused on the diagonal and two corners, so we are still in the 5-7 range even though there are 9 categories technically. However, drawbacks include losing detailed information since a large range of numbers is only split into three categories.

---
class:primary
#Redesign: Correlation

.center[

**Directly encode correlations between As Applied treatments and Yield**

]

.pull-left[
**Benefit**: Direct statement of correlation while maintaining some spatial orientation 
  - Explicit Encoding Layout `r Citep(bib[[c("gleicher2011")]])`
+ Bivariate color scale
+ Maintain some spatial information. 
  - Correlations may be impacted by field location
  
**Drawback**: complicated to connect the displayed relationship back to the data `r Citep(bib[[c("gleicher2011")]])`

].pull-right[

```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i1 <- img_modal(src = "images/corr-plot.png", alt = "Correlation")

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```
]


???

Finally, we thought it would be important to directly state the relationship between the variables to the user, so they don't have to derive it themselves. Another comparative layout, explicit encoding, directly gives the relationship to the users. So we calculated the correlation within each trial plot between the as-applied data and yield. The trial plot is to help maintain some spatial orientation. I chose a blue-white-red color scheme due to the association of blue with coolness/negative and red with warmth/positive (like a temperature map). This is a diverging color scale, with white in the middle as the neutral value. Can see for the most part, as application amount increase, so does the yield. Some areas where the inverse is true (more investigation, maybe lower, dirt differs, etc). Used a bivariate color scheme go through white color for zero. Maintaining some spatial information is important as correlation is impacted by field location. However, a major drawback is that it doesn't state the data, so we know what the correlation is, but not the values used to find it.

---
class:primary
# Redesign: Correlation with Scatterplot

**Add some context back**

.center[
```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i1 <- img_modal(src = "images/corr-with-scat2.png", alt = "Hybrid Layout", other=list(width="40%"))
i2 <- img_modal(src = "images/corr-with-scat3.png", alt = "Hybrid Layout with Hover", other=list(width="40%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i2, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9],
  str_split(i2, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```
]

+ A standard practice to overcome weakness of decontextualization is utilizing a hybrid comparative layout `r Citep(bib[[c("lyi2021")]])`
  - Juxtaposed scatterplot to the correlation plot
(combining the layouts of juxtaposition and explicit encoding). 
+ Interactivity connects the juxtaposed plots, where hovering over a trial plot in the correlation map highlights the corresponding points in the scatterplot used in the correlation calculation.

[Link](https://alisonkleffner.github.io/yield-map-redesign/interactive-example.html)

???

A  standard practice to overcome the decontextualization of the explicit encoded layout is using a hybrid layout. Here we juxtaposed a scatterplot of the data used to calculate the correlation to the correlation plot. Interactivity connects the two plots, where hovering over a trial plot in the correlation map highlights the corresponding points in the scatterplot.

---
class:primary
#Conclusion/Future Work

**Next Step**: Obtain Feedback from those using the plots (farmers, crop consultants)
- Eventually do some testing between the layouts to see which farmers are reading more accurately.


**Eventually**: Develop a R Shiny app to explaining machine learning output to non-experts
- Build trust in the model predictions without requiring farmers to learn the details of statistical modeling.
- Will utilize these plots, among others

???

The next step is to obtain feedback from those that would be actually using the plots to make any edits. And eventually I would like to do some testing between the color blending, color map, and juxtaposed correlation and scatterplot to see which are read more accurately. As I saw some mixed reviews between color blending and the color map. Eventually the plot with be utilized in an R shiny app that explains machine learning output to non-experts to help build trust in the results.

---
class:inverse

<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
.center[
# Trajectories
]

---
class:primary
# What are Trajectories?


+ Trajectories are considered the most complex form of data based on
points, but is also becoming more easily available `r Citep(bib[[c("kisilevich_spatio-temporal_nodate", "rinzivillo_visuallydriven_2008")]])`
  - Difficult to visualize effectively
  - Diverse set of properties
  - Different lengths
  
  .center[
```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i1 <- img_modal(src = "images/trajectory.png", alt = "Example of a Trajectory from Ansari et
al. (2020)", other=list(width="50%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```
]

???

Now we are going to shift gears and focus on a type of spatio-temporal data, trajectories. Trajectories are complex to work with due to multiple factors, for example, having a diverse set of properties (speed) and different length. Additionally, due to have dimensions in space and time, they are difficult to visualize effectively. However, trajectories are becoming more easily available due to tracking devices, so better ways to work with them are necessary. 



---
class:inverse

<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
.center[
# Trajectory Visual Diagnostics
]

---
class:primary
# Background

**Interest**: discover patterns within the movements to help understand the trajectories behavior`r  Citep(bib[[c("andrienko_visual_2007")]])` 

**A Method**: Visualization during Exploratory Data Analysis:  
  + Trajectories are difficult to visualize (messy)
  + Provide insight into the underlying dynamics driving movement.

**Extract Features**: Trajectories are complicated to work with, so we can extract features from the raw data that can summarize its movement `r Citep(bib[[c("climate-viz")]])` 
  + Can use visualization to motivate feature creation
  + Want to create features that provide a quantitative summary of the movement seen in plots 

**Case Study**: Arctic Sea Ice trajectories

???

Of common interest with trajectories is to discover patterns within their movements to help understand the trajectories behavior. One method to help discover these patterns is to visualize the trajectories during exploratory data analysis. These plots tend to messy due to the complexity of trajectories, but they can still provide some insight into the underlying dynamics driving movement. Since trajectories are complex, extracting features form them may make them easier to work within different methods. The features should summarize it's movement. Visualization can be used to motivate the creation of features. For example, Wu et al (2022) developed a method called TPoSTE which created features based on events to separate a boat's trajectory into period of fishing or sailing. For our process, we focus on a case study involving arctic sea ice trajectories.
---
class:primary
# Data

.center[
```{r grid-pic,  results='asis', echo = F, include = T, cache = T, eval = TRUE}

i1 <- img_modal(src = "images/rgps_grid.jpg", alt = "Example of initial grid used to track movement (Peterson & Sulsky, 2011)", other=list(width="25%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()

```
]

+ Sea Ice can be tracked by NASA's RADARSTAT Geophysical Processor System (RGPS), which uses synthetic aperture radar (SAR) images to track the trajectory of points on an ice sheet.
+ Each grid cell vertex is assigned an identifier (cell $j=1,...,n$) which is used for tracking
+ Set of all trajectories: 

.center[
$\mathcal{G} = \left\{g_1, ..., g_n\right\}$ $\\$
where $g_{j} = \left\{s_{jt} : t \in \mathcal{T}_j\right\}$, $\mathcal{T}_j \subset \left\{t=1...T\right\}$ a collection of time points where $g_j$ is observed $\\$
and ${s_{jt}}$ = $(x_{jt}, y_{jt})$
]

+ For our study region, $n$ = 8811, and $T$ = 22

???

The sea ice trajectories were tracked by NASA's RADARSTATE geophysical processor system (RGPS), which uses sequential synthetic aperture radar images to track the trajectory of point on an ice sheet. On the first day of the study period, a grid is put on the image, where each grid cell vertex is assigned an identifier (j) that is tracked over the study period using feature based and area based tracking. At the end of the study period we have a data set of n trajectories, where each trajectory is a collection of spatial locations at different times. Due to collecting this data with a satellite, not all the trajectories are observed on the same day, so we have a collection of possible times. We focused on the Beaufort region, so we have a total of 8811 trajectories on 22 possible days.

---
class:primary
# Data Difficulty

.center[
```{r traj-ex,  results='asis', echo = F, include = T, cache = T, eval = TRUE}

i1 <- img_modal(src = "images/traj-example.png", alt = "Example of a single trajectory in our data set", other=list(width="90%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()

```
]

???

This data set in particular can be complicated to work with. To show this we look at one trajectory. For example, we have missing data, where there is no pattern within the missingness, due to data collection by satellite. So gaps between observations vary between 1-3 days. Secondly, at day 5, we have two observations, so not only are we missing data, sometimes we have multiple observations on the same day, which can be difficult to account for. The plot to the left shows the path of the trajectory, where are observed locations are connected with a line segment. This shows us a depiction of what we see in the data set. It shows how visualizing the trajectories helps the user understand the movements better, so it's important to visualize the trajectories, even though they may be messy.

---
class:primary
# Gestalt Principles of Visual Perception

**Identifing Patterns**: Can use the gestalt principles of visual perception to process large amounts of data efficiently. 
+ Explains how humans naturally perceive objects and organize them in groups

.pull-left[
Principle of Similarity: group items that look similar .
  + Trajectories with similar shapes and orientations `r Citep(bib[[c("chalbi_gestalt")]])`
.center[  
```{r law-sim,  results='asis', echo = F, include = T, cache = T, eval = TRUE}

i1 <- img_modal(src = "images/law-sim.png", alt = "Example of gestalt law of similarity", other=list(width="40%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()

```
]
].pull-right[
Principle of Common Fate: group objects that share a dynamic behavior
  + Affected by the same underlying processes `r Citep(bib[[c("chalbi_gestalt", "alais-gestalt-1998")]])` 
.center[
```{r law-fate,  results='asis', echo = F, include = T, cache = T, eval = TRUE}

i1 <- img_modal(src = "images/common-fate.png", alt = "Example of gestalt law of common fate", other=list(width="60%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()

```
]]

???

Before we look at visualizations of the trajectories used during EDA, I first wanted to talk about an important tool to help extract patterns. The gestalt principles of visual perception helps users process large amounts of data efficiently by explaining how humans naturally perceive objects and organize them into groups. There are multiple, but we are going to focus on three here. The principle of similarity says that people tend to group items that look similar. So we organize trajectories with similar shapes and orientations into groups. Second is the principle of common fate used with animated graphics. This principle says that people group objects that share a dynamic behavior, like a flock of birds, as this means those objects are potentially affected by the same underlying processes. 

---
class:primary

# Static Trajectory Plot


+ Directed line segments, with the direction of each trajectory denoted by an arrow at the end `r Citep(bib[[c("andrienko_supporting_2000")]])` 
  - Shows the displacement and direction of each trajectory over time.
+ This plot violates several guidelines for effective visualization, making it
unsuitable for presentation.
  - However, using the principle of similarity helps a viewer easily group trajectories that look to move with a similar form in the same direction over time

.center[
```{r traj-pic,  results='asis', echo = F, include = T, cache = T, eval = TRUE}


i1 <- img_modal(src = "images/traj_plot.png", alt = "Plot of id trajectories to show movement and directiction of movement", other=list(width="55%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()

```
]

???

First, we created a static plot of all of our trajectories, which connected each observed location of a trajectory with a line segment, and an arrow was added to the end to show the ending direction of movement. So this plot shows the displacement and direction of each trajectory over time.This plot is messy and violates several principles of effective graphics. For example, it's cluttered (trajectories on top of each other), and the color has no meaning (was just used to help visually differentiate the different trajectories better). The coloring is potentially problematic due to the principle of similarity, a user may group all similarly colored trajectories and try to derive a relationship which would be inaccurate. However, using the principle of similarity is also helpful as we can see group of trajectories that look to move with a similar form in the same direction. These groups tend to occur in contiguous patches and stick out even though the plot is kind of a mess. So we can make an assumption, that the underlying process causing the sea ice to move changes based on the location. 

---
class:primary
# Animated Trajectory Plot

[Link](https://alisonkleffner.github.io/yield-map-redesign/traj.html)

+ Griffin, MacEachren, Hardisty, Steiner, and Li (2006) found that animated plots allowed a user to identify moving clusters easier than multiple windows of static plots. 
+ Shows the incremental progress of each trajectory over time by plotting the new
location at each time step and connecting the new observation with the previous through a line segment. 
+ New information:
  - see a trajectory speeding up or slowing down through the length of the added line segments. 
  - Associate a movement with a particular day
+ Using gestalt principle of common fate we can see that trajectories moving with a similar velocity occurs in contiguous patches.

???

Another drawback of the static trajectory plot is the inability to associated different movements with a specific time. So don't learn things related to specific times, just total time. So we can create an animation of our movement. We chose to use animation as Griffin et al (2006) found that animated plots allows users to identify moving clusters easier than multiple juxtaposed static plots. In our animated plot, we showed the incremental process of each trajectory on each day by adding the movement for a day, represented by a line segment, to the previous days movement. Now we can see the trajectory speeding up and slowing down based on the length of added line segments. Further, we can associate a movement with a particular day, like what day a trajectory changes direction. Here we can use the principle of common fate to group trajectories moving with a similar velocity (direction/speed), which once again seems to occur in contiguous patches.

---
class:primary

# Deriving Numerical Features: Bounding Box

+ We create a bounding box around for each trajectory to represent it's movement
+ Bounding Box Features:
  - Length travel in x/y between the minimum and maximum location 
.center[
( $x_{max} - x_{min}$ and $y_{max} - y_{min}$)]
  - Length travel in x/y between latest and earliest observation 
  .center[
  ( $x_{1} - x_{0}$ and $y_{1} - y_{0}$)]
  - Angle of movement (direction)

.center[
.pull-left[
```{r bb-pic1,  results='asis', echo = F, include = T, cache = T, eval = TRUE}


i1 <- img_modal(src = "images/bb_1.png", alt = "Points used to Develop Bounding Box 1", other=list(width="75%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()

```
].pull-right[

```{r bb-pic2,  results='asis', echo = F, include = T, cache = T, eval = TRUE}


i1 <- img_modal(src = "images/bb_2.png", alt = "Points used to Develop Bounding Box 2", other=list(width="55%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```

]
]

???

After visually exploring the data during exploratory data analysis, we wanted to derive numerical features based on the visualizations. This was done by creating essentially a bounding box around each trajectory, which represents its movement over time. We can then calculate different features from this bounding box. First, we can find the distance between the maximum and minimum coordinates (total displacement). Second, this value may not always represent the first and last day of the time frame, so we also found the different between the latest and earliest observation (displacement in time). Finally, using the displacement in time, we found the angle that the trajectory moved over the time frame.


---
class:primary
# Deriving Numerical Features: Wiggle

.center[
```{r wiggle,  results='asis', echo = F, include = T, cache = T, eval = TRUE}


i1 <- img_modal(src = "images/wiggle.png", alt = "Wiggle Calculation", other=list(width="50%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()

```
]

+ Each trajectory consists of multiple known points connected with line segments. 
+ To determine the amount of “wiggle”, we decided to estimate the total length of the line segment (arc length).
+ We can estimate the total length by first finding the distance between each set of two connected
points (yellow lines).
  - We then added all the calculated distances to estimate the total length of the trajectory.
+ Trajectories with a higher total length are "wigglier"

???

Next, besides the bounding box, we wanted to derive a numerical assessment of "wiggle", as this is something that can be seen but may be hard to quantify. How I began to think through this was by imaging we pulled a trajectory so that it was straight. Trajectories with more wiggle would be longer that those with less wiggle. Since each trajectory consists of observed points connected by line segments, I found the length of each line segment and atted them all together (estimate of act length). So the trajectories with a higher total length are wigglier.


---
class:primary
# Feature Selection

+ Not all characteristics of a trajectory are simultaneously relevant when
analyzing trajectories `r Citep(bib[[c("rinzivillo_visuallydriven_2008")]])`
+ Clustering algorithm to assign trajectories to groups of similar
movements 
+ No label information to help evaluate feature importance, used visualization to make judgements `r Citep(bib[[c("li-features")]])`.
  - Redundant:  adding it to the clustering algorithm, while
holding the other variables constant, does not change the assigned clusters.
  - Relevance: help with cluster continuity

.center[
```{r feat-comp,  results='asis', echo = F, include = T, cache = T, eval = TRUE}


i1 <- img_modal(src = "images/feature-comparison4.png", alt = "Subsets of Clusters to Determine Relevant Features", other=list(width="60%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()

```
]

???

Finally, not all characteristics of a trajectory are simultaneously relevant when analyzing trajectories, so we wanted to employ feature selection to assess relevancy. Since we could see the movement occurring in contiguous patches, we applied a clustering algorithm to find this groups of similar movements. So we have no label information (don't know true trajectories), we used  visualization to make judgements. So assigned each cluster a color, and output a single point of each trajectory with the assigned color onto a map. We classified redundant features as adding a feature to the clustering does not change the assigned cluster. Further, we wanted our features to help create continguous clusters. Did not text all possible subsets of features, just some I thought was relevant.  (Explain process). Plot 4 is the features selected.

---
class:primary
# Conclusion/Future Work

+ We can use messy plots to motivate the creation of numerical features to summarize trajectory movements.
+ The relevant features can be used to find groups of similar trajectories, and in future analyses as well.
+ In the future, we plan to extend our bounding box features to three dimensions through a case study of seabird flight trajectories.

???

In conclusion, we can use messy plots of trajectories to help motivate the creation of features that summarize a trajectories movements. We can also assess relevancy of the created features through visualization by visualizing the clustering of groups of similar movements. These future can then be used in future methods. In the future, we plan on extending our bounding box features into a three-dimensional bounding box through a case study of the of the trajectories of sea bird flights.

---
class:inverse

<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
.center[
# A Spatio-Temporal Model for Arctic Sea Ice
]

---
class:primary

# Importance of Studying Sea Ice

+ Sea ice acts as an insulator between the warm ocean and colder atmosphere `r Citep(bib[[c("peterson_evaluating_2011")]])`
+ Cracks, or leads, may form in the ice pack due to dynamic processes
  - Allows for heat from the ocean to be transferred to the atmosphere `r Citep(bib[[c("schreyer_elastic_2006")]])`. 
  - Accounts for half of the heat flux between the ocean and atmosphere `r Citep(bib[[c("badgley_1961")]])`
+ The state of sea ice, including lead characteristics, and understanding the dynamics driving these changes provides valuable information for weather prediction, climate models, and ocean models `r Citep(bib[[c("reiser_new_2020")]])` 


.center[
```{r ice-pic,  results='asis', echo = F, include = T, cache = T, eval = TRUE}


i1 <- img_modal(src = "images/Ice Chunk.png", alt = " Artice Sea Ice with Crack", other=list(width="35%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()

```
]

???

Sea ice is act as an insulator between the warm ocean and the colder atmosphere. Crack, or leads, form in the ice due to dynamic processes, like wind and ocean currents. When these leads for, heat from the ocean is transferred into the atmosphere, warming it (so potentially having an impact on climate change). Leads account for half of the heat flux between the ocean and the atmosphere even though they only occupy a smaller percentage of sea ice. The state of the sea ice, which includes characteristics about the lead like width, and understanding the dynamics driving movements provides valuable information for weather prediction, climate models, and ocean models. So locating these leads is important and  

---
class:primary

# Research Objectives

1. Develop a Lead detection method
  - Address some drawbacks of the other methods by using only the movement of the sea ice
  - Cluster trajectories based on movement  
  - The boundaries would be possible locations of leads, as the underlying process causes the sea ice to move differently depending on the location
2. By applying information gained from clustering, we developed a spatio-temporal model to reconstruct the underlying process, which can be used to estimate missing points along a trajectory.
  - Take into account non-stationarity of the data

???

In this project we first want to develop a lead detection method, which addresses drawbacks of the other methods which include issues with incorrectly identifying clouds as leads and inaccurate calculations of sea ice deformation. In our method, we plan to use only the movement of the sea ice. Based on visualization of the sea ice trajectories (from the previous section), we plan to cluster the trajectories based on similar movements. The boundaries between clusters would then be the locations of leads, as the underlying process shifts at this location, causing a potential split in the sea ice. Next, by applying the information gained from clustering, we developed a spatio-temporal model to reconstruct the underlying process. We then can use this to estimate missing points along a trajectory to obtain a complete set of space-time observations, which then can maybe used to calculate more accurate sea ice deformation estimates. Our will take into account the non-stationarity of our data, meaning the assumption of a global mean and covariance function would be inaccurate. Global mean and covariance is assumed in many dynamic interpolation approaches. So our model will estimate parameteres separately depending on the location.

---
class:primary
# Review of Methods

**Lead Detection**: used bounding box features in K-Means clustering, which partitions $n$ observations into $k$ clusters
+ Boundaries between clusters are the estimated locations of leads
+ Found through simulations and the sea ice trajectories that our method provides a reasonable estimation of lead locations  

**Finding Neighbors**: Using information gained from clusters to identify spatio-temporal neighbors
+ Would expect a missing point at that time to move similarly to known points in same cluster
+ Cluster trajectories by week to find neighbors
  - Intersection of one week's clusters with the week before and week after would create groups
  - Each member of a group is then a spatio-temporal neighbor of the other members as they are in a similar geographic region over time. 
  
???

For the sake of time, I'm just going to review the pieces that has not changes since my comprehensive exam. So using the features from the static visualization and feature selection in the previous section, we clustered the trajectories using k-means clustering. A drawback is that for k-means, the number of clusters must be specified prior to clusters, which we determined using the silhouette statistic. The trajectories are assigned a color based on the cluster assignment, and a point location was plotted on a plot, showing groups of contiguous clusters (like feature selection slide). We hypothesized that the boundary between clusters would be the estimated location of a lead, and we found through applying our process through simulations and the sea ice trajectories that our method provides a reasonable estimation of lead locations. 

Next, to develop our model to reconstruct the underlying process, we used the information gained from clusters to identify spatio-temporal neighbors, as we would expect a missing point to move similarly to known points in the same cluster. To find the spatio-temporal neighbors, we cluster the trajectories by week (sub-trajectories). We used by week clusters as it was the smallest interval could detect movement and also see some continuity between weeks. After clustering, we find the spatial intersection between the desired weeks clusters (week wanting to interpolate) with the week before and the week after. The groups created by these spatial intersection are considered to be spatio-temporal neighbors as they are in a similar geographic region over time.


---
class:primary

#INLA

We developed a model to reconstruct the underlying process (assumed Gaussian), where we simultaneously obtain the movement in $x$ (called $u$) and the movement in $y$ (called $v$) at time $t$.
+ The movements are added to the previous location to estimate the missing location
$$(\hat{u}_{t-1}, \hat{v}_{t-1}) + (x_{t-1}, y_{t-1}) = (\hat{x}_t, \hat{y}_t)$$


We elected to use the Integrated Nested Laplace Approximation (INLA) approach
  + Computational benefits over other methods, as it focuses on models that can be expressed as latent Gaussian Markov Random Fields (GMRF)
  + Easily accounts for the spatio-temporal structure of the data during the inferential process `r Citep(bib[[c("spde-book")]])`


???

We wanted to develop a model that reconstructs the assumed Gaussian underlying process, where we can jointly obtain the movement in x (called u) and the movement in y (called v) at time t. We can then add these movements to the previous location to estimate the missing location (explain the equation). We elected to use the integrated nested laplace approximation or INLA to create our models due to their compuational benefits over other methods since it focuses on models that can be expressed as latent gaussian markov random fields (see where later). Additionally, they provide flexibility to easily account for the spatio-temporal data during the underlying process. 

---
class:primary

#INLA: Continuously Indexed GF

Bivariate Data can be defined by the joint process: $$\left\{H(s,t), (s,t) \in \mathcal{D} \in \mathcal{R}\right\}$$ where there are $N$ spatial locations at $t$ time points.

The process is assumed Gaussian, where the model can be rewritten as 
$$H_{{i,t}} \sim BivN(\eta_{i,t}, \sigma^2_e)$$ 
with $\sigma^2_e$ representing the nugget effect and the linear predictor is defined as 

$$\eta_{i,t} = \alpha + w_{i,t}$$ 
with $\alpha$ denoting the intercept and the realization of the latent ST Gaussian Field (GF) is represented by $w \sim GF(0,\Sigma)$. The covariance function $(\Sigma)$ is the separable Matern ST covariance function `r Citep(bib[[c("BLANGIARDO201333")]])`. 

???

To begin setting up our model, we can define out bivariate data by the joint process H, where we have n spatial locations at t time points. We assume the process is Gaussian so we can rewrite the model as $H_{{i,t}} \sim BivN(\eta_{i,t}, \sigma^2_e)$, where the sigma squared e represents the nugget effect (or measurement error) and our linear predictor eta is expressed as alpha, the intercept plus the realization of the latent spatio-temporal Gaussian field, w. The realization has a separable matern spatio temporal covariance function. 

---
class:primary

#INLA: SPDE

When working with point data (like our trajectories), assuming a continuously indexed GF for $w_{i,t}$ is not a computationally efficient approach.

Instead used stochastic partial differential equations (SPDE)- represent a GF with Matern Covariance Function through a discretely indexed process called a GMRF `r Citep(bib[[c("spde-book")]])`
.pull-left[
- Discrete Index is created with a constrained delaunay triangulation
.center[
```{r spde,  results='asis', echo = F, include = T, cache = T, eval = TRUE}


i1 <- img_modal(src = "images/mesh-ex.png", alt = "Example of the triangulation of a field used in our simulation study", other=list(width="90%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()

```
]].pull-right[
  
The linear predictor can then be rewritten as 
$$\eta_{i,t} = \alpha + \sum^{G}_{g=1}\tilde{A}\tilde{w}$$ 
where $\tilde{A}$ is a sparse precision matrix mapping the GMRF, $\tilde{w}$, from $N$ locations to the $G$ nodes in the triangulation
]

???

When working with point data like our trajectories, assuming a continuously indexed gaussian field for w is not a computationally efficient approach. So instead we used stochastic partial differential equations. These represent a gaussian field with a matern covariance function through a discretely indexed process called a gaussian markov random field. To create the discrete index, a constrained delaunay triangulation. This triangluation prevents highly obtuse triangles, and we create triangles outside the boundary to prevent the variance being significantly higher at the boundary points (boundary effect). In this figure, an example of simulated data is given. On the right hand side is the data, which a blue line around the points to show the boundary. The left hand side shows the triangulation of this space, with the same blue line, where we see more triangles on the inside than outside. The density of the triangles also affects computation time.

Since we are using the stochastic partial differential equations, the linear predictors is rewritten, where we still have our intercept, but the A tilde is a sparse precision matrix that maps the GMRF, w, from the N locations in the data set to the G nodes in the triangulation. 

---
class:primary
#Final Model

Specifically for our model to jointly measure the underlying process, the linear predictor is written as
$$\eta_{it} = \alpha_u + \alpha_{v} + z_{u}(s,t) + z_{v}(s,t) + z_{uv}(s,t)$$

where $\alpha_u$ and $\alpha_{v}$ are the intercepts for each response and the $z$ functions represent the SPDE model for the $u$ and $v$ spatio-temporal effects, along with their interaction.

We developed a model within each intersection to account for the non-stationary aspect of our data using only the data at time t, only data from t − 1, t, and t + 1. 

**Using Model**: Create a spatial grid encompassing the sea ice. 
  + The centroid of the grid cells become a starting estimation of the missing $g_j$. 
  + The underlying process should be smooth within an intersection, so the centroid should have a similar value of the underlying process. 
  
???

So for our final model to jointly measure u and v of the underlying process, we write the linear predictor as $\eta_{it} = \alpha_u + \alpha_{v} + z_{u}(s,t) + z_{v}(s,t) + z_{uv}(s,t)$, where we have our intercepts for each variable and the z functions represent the SPDE model for u and v spatio-temporal effects, along with their interaction. We developed a model within each intersection to account for the non-stationarity aspect of our data, using only data at time t, t-1, t+1. Only used three days as already computationally inefficient, and don't expect days further out to have much of an impact. 

Once we develop the model, we created a spatial grid that encompassed the sea ice to obtain values to use in our model (centroid of the grid cell). The underlying process should be smooth within an intersection, so the centroid should be close enough that it has a similar value of the underlying process. Once we create the grid for initial location estimates of the missing data, we used the developed bivariate model to find the predicted locations using the posterior mean of the linear predictor. The estimates are added to the previous day's known location to obtain the esimate of the missing location.

---
class:primary
#Overview of Results from Simulation Study

Compared four different methods:
  + Linear Interpolation
  + Joint Nonstationary Spatio-Temporal Model
  + Joint Nonstationary Spatial Model with time fixed effect
  + Joint Stationary Spatio-Temporal Model
  
Results:
  + Joint Stationary Spatio-Temporal Model generally performs the worst
  + The spatial model with fixed time (for $y$) and the spatio-temporal model (for $x$) perform better than linear interpolation for less smooth underlying processes

???

To test our methods, we conducted a simulation study, but for times sake I'm just going to show the interesting results. First we compared four different methods for finding missing points of the trajectories. First, we used linear interpolation, which is the simplest method to interpolate trajectory data. It estimates a missing point on a straight-line path between two observed locations. Second is our described model. Third, is we used the same process, but them model is a spatial model with a fixed time effect due to only have three days in the model. Finally, we created a stationary spatio-temporal model to check if our non-stationarity approach is valid, so our inla with spde model was created using the whole data set, not in each intersection.

Performance was assessed using the root mean square error. The stationary model generally performs the worst, validating our non-stationarity modeling approach. The spatial model with fixed time (for $y$) and the spatio-temporal model (for $x$) perform better than linear interpolation for less smooth underlying processes. I found it interesting that our models tended to perform worse for x than y, meaning it doesn't perform as well for the second variable.


---
class:primary
#Sea Ice Trajectory Interpolation

+ Due to observing most of the ice sheet every three days, our response in the model was the movement over three days, meaning 
$$(\hat{u}_{t-3}, \hat{v}_{t-3}) + (x_{t-3}, y_{t-3}) = (\hat{x}_t, \hat{y}_t)$$
+ Of the observed data in an intersection with a known location after three days, we randomly removed 10%
+ We fit the spatial model with a time fixed effect 
  - Computationally more efficient than the spatio-temporal model. 
  - Only using three days to developour model, so there is probably not a significant amount of temporal
dependence.
  - Finally, it performs better for $y$, the already worse performing coordinate in the simulation study

???

Now I'm going to walk through some of the results for our model using the sea ice trajectories. For testing, we created a model for each intersection and time combination. So if we had p intersections, which vary by week, and t time points, then t x p models are developed. Due to observing most of the ice sheet every three days, our response in the model was the movement over three days. Of the observed data in an intersection with a known location after three days, we randomly removed 10%. Then using the observed data, we fit the spatial model with a time fixed effect as it is computationally more efficient than the spatio-temporal model. Also, since we are only using three days to develop our model, there is probably not a significant amount of temporal dependence, as shown in the simulation study, where the spatial model sometimes performs better than the spatio-temporal model (for y). This model was used to estimate the underlying process that drives movement over three days.



---
class:primary
#Example Results - Week 1

```{r ice-results-tab2, message=FALSE, warning = FALSE}

result_data5 <- data.frame(Cluster = c(1,2,3,4,5,6), X1 = c(4.410,0.443,1.120,1.140,0.549, 1.320), Y1 = c(15.500, 0.870, 1.480, 1.980, 1.980, 2.970), X2 = c(1.330, 0.303, 1.770, 2.920, 0.969,2.330), Y2 = c(21.800, 0.527, 4.740, 3.420, 5.507, 7.450))

kableExtra::kable(result_data5, booktabs = TRUE, caption = "RMSE for Interpolation Methods by cluster for Week 1", col.names = c( "Cluster", "X", "Y", "X", "Y"), escape = FALSE, align = "c", table.attr = "style='width:80%;'") %>% add_header_above(c(" ", "Joint Spatial" = 2, "Linear" = 2)) 

```


???

For time, I am just showing the RMSE results for Week 1. Once again, we are comparing it with linear interpolation. Overall our model seems to be performing better than linter interpolation. However, since each cluster is made of different movements we also Look at the RMSEs for each cluster, for x, in week 1, our model performs better than linear interpolation for cluster 3 through 6. The results for the y coordinate are similar, except in week 1, our model also performs better in cluster 1


---
class:primary

#Visual of Clusters to Describe Results

+ Black Polygon (Cluster 4): Data is More Spread out and not linear
+ Red Polygon (Cluster 2): Data does not move much

.center[
```{r clust-help,  results='asis', echo = F, include = T, cache = T, eval = TRUE}

i1 <- img_modal(src = "images/inset-traj-plot.png", alt = "Overall trajectory plot with colored polygons to denote the location of the broken out clusters", other=list(width="80%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()

```

]

???

This plot is just to obtain a visual idea of what kinds of movement lead to a better peformance of our model. So as example, the black polygon represents cluster 4, where our model performs best. Here the data is more spread out and not linear, so would not expect linear interpolation to work well here. Second, the red polygons refer to cluster 2, here the data does not move much over the week, allows for linear interpolation to have an easier time interpolating between two close points. So our model shows promise for curved data that is not highly sampled.

---
class:primary

#Coverage 

A benefit of using a model-based approach is that we can determine the uncertainty of our estimate.
  - Standard deviation of estimate computed using the posterior marginals, which are then used to create an interval of our estimates
  - The intervals can then be used to find the proportion of intervals containing the true amount of movement during testing of our models, otherwise known as coverage

<br>

```{r ice-results-tab3, message=FALSE, warning = FALSE}

result_data6 <- data.frame(Week = c(1,2,3), X1 = c(0.389, 0.451, 0.443), Y1 = c(0.37, 0.476, 0.373))

kableExtra::kable(result_data6, booktabs = TRUE, caption = "<b>Coverage</b>", col.names = c( "Week", "X", "Y"), escape = FALSE, align = "c", table.attr = "style='width:75%;'")
```


???

A benefit of using a model-based approach is that we can determine the uncertainty of our estimate. Using the posterior marginals, we can find the standard deviation of the estimate, which can then be used to create an interval of our estimates. The intervals can then be used to find the proportion of intervals containing the true amount of movement during testing of our models, otherwise known as coverage. Our coverage is pretty low, which is some cause for concern. So there is maybe better priors to use in our inla model, or a better creation of the triangulation, etc. 

---
class:primary

# Discussion of Model


**Advantages**:

+ Takes into account the nonstationarity of the data
+ Showed some improvement, in terms of RMSE, over linear interpolation for curved data that is not highly sampled
+ Able to estimate data on first and last day of a dataset, which linear interpolation is not able to do. 
+ Able to calculate uncertainty
  
**Areas for Improvement**:

+ Computational efficiency
+ Coverage shows that there is room for improvement with the prior specification

???

Our model is beneficial as it takes into account the non-stationarity of the data, which is an important component of this specific underlying process. And it Showed some improvement, in terms of RMSE, over linear interpolation for curved data that is not highly sampled. Also, it is able to estimate days on the edges, which linear interpolation is not able to do since it requires two observed locations to estimate in between. Finally we can calculate an uncertainty estimate of our predictions. 

Areas of improvement for our approach include computational efficiency. Due to develop t x p (number of intersections) models, it takes a long time to run (~20-45 minutes). Next, coverage showed there is room for improved with prior specification. Currently assuming the same prior for each model (more efficient), but probably not accurate.

  
---
class:primary

#Future Work

+ Different method to determine number of clusters for lead detection.
  - For example, `r Citep(bib[[c("ossama_extended_2011")]])` has a process for determining the number of unique directions, which may be a better estimate of $k$. 
+ Methods to improve computational efficiency should be considered (parallel computing).
+ Currently, our interpolation method is a two-step process: find clusters and create model in each cluster. 
  - Eventually, we would like to turn this into a one-step process, potentially using Voronoi tessellations and a piecewise Gaussian Process. 
  - Combining everything into one step may also increase computational efficiency.

???

In the future, for lead detection, I would like to use a better method for determining the number of clusters. For example Ossama et al (2011) has a process for determining the number of unique directions, which may be a better estimate of $k$. Second, methods to improve computational efficiency should be considered, like maybe parallel computing. Finally, probably the most important is that currently, our interpolation method is a two-step process: find clusters and create model in each cluster. Eventually, we would like to turn this into a one-step process, potentially using Voronoi tessellations and a piecewise Gaussian Process. Combining everything into one step may also increase computational efficiency.

---
class:primary
# References

<font size="2">
```{r, print_refs1, results='asis', echo=FALSE, warning=FALSE, message=FALSE}
print(bib[[c("alais-gestalt-1998", "andrienko_supporting_2000",
"andrienko_visual_2007",
"ansari_spatiotemporal_2020",
"badgley_1961",
"biesecker-2020",
"billen_nitrogen_2013",
"BLANGIARDO201333",
"BRAVO2004b",
"BRAVO2004a",
"brewer_2002"
)]], 
      .opts = list(check.entries = FALSE, style = "html", bib.style = "authoryear")
      )
```
</font>

---
class:primary
# References
<font size="2">
```{r, print_refs2, results='asis', echo=FALSE, warning=FALSE, message=FALSE}
print(bib[[c("chalbi_gestalt",
"leaflet",
"cleveland_graphical_1984",
"gleicher2011",
"gordon_2015",
"griffin-maps-2006",
"climate-viz",
"he-mult-2019",
"huang2009"
)]], 
      .opts = list(check.entries = FALSE, style = "html", bib.style = "authoryear")
      )
```


</font>

---
class:primary
# References

<font size="2">
```{r, print_refs3, results='asis', echo=FALSE, warning=FALSE, message=FALSE}
print(bib[[c("key_detectability_1993",
"kisilevich_spatio-temporal_nodate",
"klippel-tobler-2011",
"kodinariya_2013",
"spde-book",
"Leonowicz2003RESEARCHOT",
"li-features",
"light-rainbow-2004",
"lyi2021",
"macdonald_1999"
)]], 
      .opts = list(check.entries = FALSE, style = "html", bib.style = "authoryear")
      )
```
</font>

---
class:primary
# References

<font size="2">
```{r, print_refs4, results='asis', echo=FALSE, warning=FALSE, message=FALSE}
print(bib[[c("MAHESWARI2017175",
"maxwell-farm-2018",
"Miller1956TheMN",
"ossama_extended_2011",
"peterson_evaluating_2011",
"reiser_new_2020",
"rinzivillo_visuallydriven_2008",
"schreyer_elastic_2006",
"SILVA2011320",
"strode-2020"
)]], 
      .opts = list(check.entries = FALSE, style = "html", bib.style = "authoryear")
      )
```
</font>

---
class:primary
# References

<font size="2">
```{r, print_refs5, results='asis', echo=FALSE, warning=FALSE, message=FALSE}
print(bib[[c("tilman_sustainalbe_2011",
"trevisan-spatial-2021",
"vanderplas2020",
"wagemans-2012-a",
"wagemans-2012-b",
"wang_comp18",
"wong2011color",
"wu-fish-2022",
"yuan_review_2017"

)]], 
      .opts = list(check.entries = FALSE, style = "html", bib.style = "authoryear")
      )
```
</font>

---
class:primary
#Acknowledgements


---
class:inverse
<br>
<br>
<br>
.center[
# Questions?
<br>
<br>

]

---
class:primary
#Number of Categories

Number of categorical scales should be limited to **5-7 categories** `r Citep(bib[[c("Miller1956TheMN")]])`
.pull-left[
- Due to working memory limits `r Citep(bib[[c("macdonald_1999")]])`
  + Harder for the user to distinguish between colors and remember the meaning of colors. 
- The load on the user’s working memory leads to an increase in the time it takes for the user to comprehend the plot `r Citep(bib[[c("huang2009")]])`
].pull-right[  
  
.center[
```{r results='asis', echo = F, include = T, cache = T, eval = TRUE}
i1 <- img_modal(src = "images/categories.png", alt = "Example 1", other=list(width="50%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()
```
]  

]

**Next:** Redesign Process

???

Additionally, the number of categories on our scale for yield should be limited to 5-7 categories (DIFM plot violates this). The categories need to be limited due to working memory limits and it makes it harder for the user to distinguish between colors and remember the meaning of what group the color is representing (might associate a color with the incorrect category). This load on the user's working memory lead to an increase in time for them to comprehend the plot, which is not something we want especially for non-experts. 

Next I am going to walk through our redesign process.



---
class:primary

# Other Lead Detection Methods

.pull-left[
**Thermal**
+ Surface temperature differs between a lead and the surrounding sea ice.
+ Use thermal channels of the Advanced Very High Resolution Radiometer (AVHRR) `r Citep(bib[[c("key_detectability_1993")]])` 
  - Heavily dependent on clear skies and has issues with thin ice
+ Methods have been proposed to reduce the impact of clouds 
.center[
```{r thermal-pic,  results='asis', echo = F, include = T, cache = T, eval = TRUE}


i1 <- img_modal(src = "images/thermal_example.png", alt = " Output from a Thermal Algorithm (Rohrs et al, 2012)", other=list(width="40%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()

```
]
].pull-right[
**Deformation**
+ Cell deformation is determined by point motion `r Citep(bib[[c("peterson_evaluating_2011")]])`
    - The determinant of the deformation gradient measures accumulated area changes
    - Can find the size and orientation
+ Drawbacks
  - Need complete set of space-time observations to calculate deformation
  - Underestimation of error in deformation product

.center[
```{r deformation-pics,  results='asis', echo = F, include = T, cache = T, eval = TRUE}

i1 <- img_modal(src = "images/kinematic_crack_algorithm.png", alt = "Example of detected leads using a kinematic crack algorithm which uses the determinant of the deformation gradient to detect leads (Peterson & Sulsky, 2011)", other=list(width="30%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()

```

]
]

---
class:primary

#Missing Data

+ In general, data collection methods may fail, leaving positions in a trajectory unknown or may want to overcome sampling sparseness
+ In our case, missing data is due to the path of the satellite used to collect the data. 

.center[
```{r missing-pic,  results='asis', echo = F, include = T, cache = T, eval = TRUE}


i1 <- img_modal(src = "images/data_example.jpeg", alt = "Missing Data within the Ice Sheet", other=list(width="50%"))

c(str_split(i1, "\\n", simplify = T)[1:2],
  str_split(i1, "\\n", simplify = T)[3:9]
  ) %>% paste(collapse = "\n") %>% cat()

```
]

???

When collecting data by satellite, the path of the satellite doesn't observe the whole ice sheet every day, leaving positions in a trajectory unknown. Missingness tends to occur in spatial chunks, which is a reason why many simple interpolation methods are not useful either. For example, this figure shows the location of each trajectory on the first day of the data set. The uncolored boxes represent missing locations, which we can see occurs in a large spatial chunk.



